{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KtCsEtuLS8s4"
   },
   "source": [
    "for the run over the general methodology, refer to \"general_training_methodology.md\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UtruyBuA-PL1"
   },
   "source": [
    "Let's import the libraries we'll be needing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JaujOauy-Nm3"
   },
   "outputs": [],
   "source": [
    "#cross-validation & tuning\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#dimensionality-reduction & tools\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkT7PYawX2JK"
   },
   "source": [
    "Let's import our data and define our train and test values. The 'label' column is the encoded output (0 for healthy control, 1 for Parkinson's disease). We'll split out train/test data, leaving a 20% holdout test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "64y2B3UAX7Hk"
   },
   "outputs": [],
   "source": [
    "csv_path = \"/content/drive/MyDrive/openSMILE_GeMAPSv01b.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "X = df.drop(columns=['label', 'Sex', 'ID', 'Age'], axis=1)\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4tN9wCJ5_Ct9"
   },
   "source": [
    "parameter grid definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "qR5i4rq--ibT"
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"lr\": {\n",
    "        \"pca__n_components\": [5, 10, 15, 20, 25, 30],\n",
    "        \"model__C\": [0.01, 0.1, 1, 10],\n",
    "        \"model__penalty\": [\"l2\"],\n",
    "        \"model__solver\": [\"lbfgs\"]\n",
    "    },\n",
    "    \"svm\": {\n",
    "        \"pca__n_components\": [5, 10, 15, 20, 25, 30],\n",
    "        \"model__C\": [0.1, 1, 10],\n",
    "        \"model__kernel\": [\"linear\", \"rbf\"],\n",
    "        \"model__gamma\": [\"scale\", \"auto\"]\n",
    "    },\n",
    "    \"rf\": {\n",
    "        \"pca__n_components\": [5, 10, 15, 20, 25, 30],\n",
    "        \"model__n_estimators\": [50, 100],\n",
    "        \"model__max_depth\": [3, 5],\n",
    "        \"model__min_samples_split\": [5, 10],\n",
    "        \"model__min_samples_leaf\": [1, 5]\n",
    "    },\n",
    "    \"xgb\": {\n",
    "        \"pca__n_components\": [5, 10, 15, 20, 25, 30],\n",
    "        \"model__n_estimators\": [100, 200],\n",
    "        \"model__max_depth\": [3, 6, 10],\n",
    "        \"model__learning_rate\": [0.01, 0.1, 0.2]\n",
    "    },\n",
    "    \"knn\": {\n",
    "        \"pca__n_components\": [5, 10, 15, 20, 25, 30],\n",
    "        \"model__n_neighbors\": [3, 5, 7, 9],\n",
    "        \"model__weights\": [\"uniform\", \"distance\"]\n",
    "    },\n",
    "    \"gb\": {\n",
    "        \"pca__n_components\": [5, 10, 15, 20, 25, 30],\n",
    "        \"model__n_estimators\": [50, 100],\n",
    "        \"model__max_depth\": [3, 5],\n",
    "        \"model__learning_rate\": [0.05, 0.1]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ko8aHPyXOpe"
   },
   "source": [
    "we now define our models array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "xBgaxewlUnL7"
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"lr\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"rf\": RandomForestClassifier(random_state=42),\n",
    "    \"svm\": SVC(random_state=42, probability=True),\n",
    "    \"xgb\": XGBClassifier(eval_metric='logloss', colsample_bytree=0.8, gamma=0, min_child_weight=1, subsample=0.6, random_state=42),\n",
    "    \"knn\": KNeighborsClassifier(),\n",
    "    \"gb\": GradientBoostingClassifier(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B9PkANeDXTlD"
   },
   "source": [
    "Training and Validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1561312,
     "status": "ok",
     "timestamp": 1756804451060,
     "user": {
      "displayName": "Vivienne Bailo",
      "userId": "01903770756516003996"
     },
     "user_tz": -180
    },
    "id": "091bc5bb",
    "outputId": "b950386f-6a7d-4839-da1d-62c74fffd610"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running grid search for lr\n",
      "Fitting 65 folds for each of 24 candidates, totalling 1560 fits\n",
      "\n",
      "Best parameters for lr:\n",
      "  model__C: 0.1\n",
      "\n",
      "  model__penalty: l2\n",
      "\n",
      "  model__solver: lbfgs\n",
      "\n",
      "  pca__n_components: 30\n",
      "\n",
      "\n",
      "Classification Report for lr:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.78      0.74         9\n",
      "           1       0.71      0.62      0.67         8\n",
      "\n",
      "    accuracy                           0.71        17\n",
      "   macro avg       0.71      0.70      0.70        17\n",
      "weighted avg       0.71      0.71      0.70        17\n",
      "\n",
      "\n",
      "Test AUC for lr: 0.8333\n",
      "Running grid search for svm\n",
      "Fitting 65 folds for each of 72 candidates, totalling 4680 fits\n",
      "\n",
      "Best parameters for svm:\n",
      "  model__C: 0.1\n",
      "\n",
      "  model__gamma: scale\n",
      "\n",
      "  model__kernel: linear\n",
      "\n",
      "  pca__n_components: 30\n",
      "\n",
      "\n",
      "Classification Report for svm:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78         9\n",
      "           1       0.75      0.75      0.75         8\n",
      "\n",
      "    accuracy                           0.76        17\n",
      "   macro avg       0.76      0.76      0.76        17\n",
      "weighted avg       0.76      0.76      0.76        17\n",
      "\n",
      "\n",
      "Test AUC for svm: 0.7986\n",
      "Running grid search for rf\n",
      "Fitting 65 folds for each of 96 candidates, totalling 6240 fits\n",
      "\n",
      "Best parameters for rf:\n",
      "  model__max_depth: 3\n",
      "\n",
      "  model__min_samples_leaf: 1\n",
      "\n",
      "  model__min_samples_split: 5\n",
      "\n",
      "  model__n_estimators: 50\n",
      "\n",
      "  pca__n_components: 15\n",
      "\n",
      "\n",
      "Classification Report for rf:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.78      0.70         9\n",
      "           1       0.67      0.50      0.57         8\n",
      "\n",
      "    accuracy                           0.65        17\n",
      "   macro avg       0.65      0.64      0.64        17\n",
      "weighted avg       0.65      0.65      0.64        17\n",
      "\n",
      "\n",
      "Test AUC for rf: 0.7083\n",
      "Running grid search for xgb\n",
      "Fitting 65 folds for each of 108 candidates, totalling 7020 fits\n",
      "\n",
      "Best parameters for xgb:\n",
      "  model__learning_rate: 0.1\n",
      "\n",
      "  model__max_depth: 3\n",
      "\n",
      "  model__n_estimators: 100\n",
      "\n",
      "  pca__n_components: 5\n",
      "\n",
      "\n",
      "Classification Report for xgb:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.78      0.74         9\n",
      "           1       0.71      0.62      0.67         8\n",
      "\n",
      "    accuracy                           0.71        17\n",
      "   macro avg       0.71      0.70      0.70        17\n",
      "weighted avg       0.71      0.71      0.70        17\n",
      "\n",
      "\n",
      "Test AUC for xgb: 0.6944\n",
      "Running grid search for knn\n",
      "Fitting 65 folds for each of 48 candidates, totalling 3120 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 34\u001b[0m\n\u001b[0;32m     15\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline(steps\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     16\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m'\u001b[39m, StandardScaler()),\n\u001b[0;32m     17\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m'\u001b[39m, PowerTransformer(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myeo-johnson\u001b[39m\u001b[38;5;124m'\u001b[39m)),\n\u001b[0;32m     18\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpca\u001b[39m\u001b[38;5;124m'\u001b[39m, PCA()),\n\u001b[0;32m     19\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m, models[model_name])\n\u001b[0;32m     20\u001b[0m ])\n\u001b[0;32m     23\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[0;32m     24\u001b[0m     pipeline, \u001b[38;5;66;03m#this implements fit and predict functions\u001b[39;00m\n\u001b[0;32m     25\u001b[0m     params, \u001b[38;5;66;03m#our params to test\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     31\u001b[0m \n\u001b[0;32m     32\u001b[0m )\n\u001b[1;32m---> 34\u001b[0m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Make predictions with the best model\u001b[39;00m\n\u001b[0;32m     37\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m grid\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\maryb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\maryb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1020\u001b[0m     )\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1024\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\maryb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1571\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1570\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1571\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\maryb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    967\u001b[0m         )\n\u001b[0;32m    968\u001b[0m     )\n\u001b[1;32m--> 970\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    986\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    993\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\maryb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\maryb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\maryb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\maryb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=8, n_repeats=15, random_state=123) #the cross validation method we'll use across models\n",
    "results = [] #to store metrics, accuracy scores and all other\n",
    "best_models={}\n",
    "\n",
    "for model_name, params in param_grid.items():\n",
    "    print(f\"Running grid search for {model_name}\")\n",
    "\n",
    "    #creating different pipelines\n",
    "\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('scaler', StandardScaler()), #feature scaling\n",
    "        ('pca', PCA()), #feature selection\n",
    "        ('model', models[model_name]) \n",
    "    ])\n",
    "\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        pipeline, #this implements fit and predict functions\n",
    "        params, #our params to test\n",
    "        cv=cv,\n",
    "        scoring='roc_auc',\n",
    "        n_jobs=-1, # parallel computing, use all cores\n",
    "        verbose=1,\n",
    "        return_train_score=True, # To get training scores as well\n",
    "\n",
    "    )\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    #make predictions with the best model (meaning with best params)\n",
    "    y_pred = grid.best_estimator_.predict(X_test)\n",
    "    y_pred_proba = grid.best_estimator_.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "    # calculate metrics on the test set\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    test_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "\n",
    "    results.append({\n",
    "        'model': model_name,\n",
    "        'test_accuracy': accuracy,\n",
    "        'test_precision': precision,\n",
    "        'test_recall': recall,\n",
    "        'test_f1': f1,\n",
    "        'test_auc': test_auc,\n",
    "        'best_params': grid.best_params_,\n",
    "    })\n",
    "\n",
    "    best_models[model_name] = grid.best_estimator_\n",
    "\n",
    "    # display best parameters\n",
    "    print(f\"\\nBest parameters for {model_name}:\")\n",
    "    for param, value in grid.best_params_.items():\n",
    "        print(f\"  {param}: {value}\\n\")\n",
    "\n",
    "    # display classification report\n",
    "    print(f\"\\nClassification Report for {model_name}:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    #dissplay AUC\n",
    "    print(f\"\\nTest AUC for {model_name}: {test_auc:.4f}\")\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 331,
     "status": "ok",
     "timestamp": 1756804451065,
     "user": {
      "displayName": "Vivienne Bailo",
      "userId": "01903770756516003996"
     },
     "user_tz": -180
    },
    "id": "4elPJZLAif04",
    "outputId": "27ad8aa2-e9f9-4d39-cb8e-b055117b6e3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODELS RANKED BY AUC SCORE\n",
      "model  test_auc  test_accuracy  test_precision  test_recall  test_f1\n",
      "   lr  0.833333       0.705882        0.706723     0.705882 0.703818\n",
      "  svm  0.798611       0.764706        0.764706     0.764706 0.764706\n",
      "   rf  0.708333       0.647059        0.650624     0.647059 0.639496\n",
      "  xgb  0.694444       0.705882        0.706723     0.705882 0.703818\n"
     ]
    }
   ],
   "source": [
    "# dispaly models sorted by auc\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"MODELS RANKED BY AUC SCORE\")\n",
    "print(results_df.sort_values('test_auc', ascending=False)[['model', 'test_auc', 'test_accuracy', 'test_precision', 'test_recall', 'test_f1']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculating mean CV AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22435,
     "status": "ok",
     "timestamp": 1756804473487,
     "user": {
      "displayName": "Vivienne Bailo",
      "userId": "01903770756516003996"
     },
     "user_tz": -180
    },
    "id": "hr-RJFpdWV5d",
    "outputId": "24b9607f-1e67-4646-9656-e4c32e0b8b1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: Mean CV AUC = 0.7145 (±0.1705)\n",
      "svm: Mean CV AUC = 0.6599 (±0.1857)\n",
      "rf: Mean CV AUC = 0.6659 (±0.1653)\n",
      "xgb: Mean CV AUC = 0.6382 (±0.1733)\n",
      "\n",
      "================================================================================\n",
      "MODELS RANKED BY MEAN CV AUC\n",
      "model  mean_cv_auc  std_cv_auc  test_auc\n",
      "   lr     0.714543    0.170452  0.833333\n",
      "   rf     0.665865    0.165307  0.708333\n",
      "  svm     0.659856    0.185653  0.798611\n",
      "  xgb     0.638221    0.173273  0.694444\n"
     ]
    }
   ],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=8, n_repeats=15, random_state=123) #the cross validation method we'll use across models\n",
    "cv_auc_scores = {}  #dict to store CV AUC scores for each model\n",
    "\n",
    "for model_name in best_models.keys():\n",
    "    #best parameters for the current model\n",
    "    best_params = results_df[results_df['model'] == model_name]['best_params'].iloc[0]\n",
    "\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('pca', PCA()),\n",
    "        ('model', models[model_name])\n",
    "    ])\n",
    "    pipeline.set_params(**best_params)\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        pipeline,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        scoring='roc_auc',\n",
    "        cv=cv,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    cv_auc_scores[model_name] = {\n",
    "        'mean_cv_auc': scores.mean(),\n",
    "        'std_cv_auc': scores.std()\n",
    "    }\n",
    "\n",
    "    print(f\"{model_name}: Mean CV AUC = {scores.mean():.4f} (±{scores.std():.4f})\")\n",
    "\n",
    "#add CV AUC metrics to results_df so we can access them later\n",
    "results_df['mean_cv_auc'] = results_df['model'].map(lambda x: cv_auc_scores[x]['mean_cv_auc'])\n",
    "results_df['std_cv_auc'] = results_df['model'].map(lambda x: cv_auc_scores[x]['std_cv_auc'])\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"MODELS RANKED BY MEAN CV AUC\")\n",
    "print(results_df.sort_values('mean_cv_auc', ascending=False)[['model', 'mean_cv_auc', 'std_cv_auc', 'test_auc']].to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOWhEDViGkOX5hG2CyN7FAE",
   "mount_file_id": "1apF8ufATiDKPH7_tGhUEzUiR53J6oMCe",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
