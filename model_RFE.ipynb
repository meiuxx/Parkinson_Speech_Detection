{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KtCsEtuLS8s4"
   },
   "source": [
    "for the run over the general methodology, refer to \"general_training_methodology.md\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UtruyBuA-PL1"
   },
   "source": [
    "Let's import the libraries we'll be needing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3227,
     "status": "ok",
     "timestamp": 1756803936950,
     "user": {
      "displayName": "Vivienne Bailo",
      "userId": "01903770756516003996"
     },
     "user_tz": -180
    },
    "id": "JaujOauy-Nm3"
   },
   "outputs": [],
   "source": [
    "#cross-validation & tuning\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.metrics import recall_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "#dimensionality-reduction & tools\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkT7PYawX2JK"
   },
   "source": [
    "Let's import our data and define our train and test values. The 'label' column is the encoded output (0 for healthy control, 1 for Parkinson's disease). We'll split out train/test data, leaving a 20% holdout test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 696,
     "status": "ok",
     "timestamp": 1756810009460,
     "user": {
      "displayName": "Vivienne Bailo",
      "userId": "01903770756516003996"
     },
     "user_tz": -180
    },
    "id": "64y2B3UAX7Hk"
   },
   "outputs": [],
   "source": [
    "csv_path = '/content/drive/MyDrive/openSMILE_GeMAPSv01b.csv'\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "X = df.drop(columns=['label', 'Sex', 'ID'], axis=1)\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4tN9wCJ5_Ct9"
   },
   "source": [
    "parameter grid definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1756803938189,
     "user": {
      "displayName": "Vivienne Bailo",
      "userId": "01903770756516003996"
     },
     "user_tz": -180
    },
    "id": "qR5i4rq--ibT"
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"lr\": {\n",
    "        \"rfe__n_features_to_select\": [5, 10, 15, 20, 25, 30],\n",
    "        \"model__C\": [0.01, 0.1, 1, 10],\n",
    "        \"model__penalty\": [\"l2\"],\n",
    "        \"model__solver\": [\"lbfgs\"]\n",
    "    },\n",
    "    \"svm\": {\n",
    "        \"rfe__n_features_to_select\": [5, 10, 15, 20, 25, 30],\n",
    "        \"model__C\": [0.1, 1, 10],\n",
    "        \"model__kernel\": [\"linear\", \"rbf\"],\n",
    "        \"model__gamma\": [\"scale\", \"auto\"]\n",
    "    },\n",
    "    \"rf\": {\n",
    "        \"rfe__n_features_to_select\": [5, 10, 20, 30, 40, 50],\n",
    "        \"model__n_estimators\": [50, 100],\n",
    "        \"model__max_depth\": [3, 5],\n",
    "        \"model__min_samples_split\": [5, 10],\n",
    "        \"model__min_samples_leaf\": [1, 5]\n",
    "    },\n",
    "    \"xgb\": {\n",
    "        \"rfe__n_features_to_select\": [5, 10, 20, 30, 40, 50, 'all'],\n",
    "        \"model__n_estimators\": [100, 200],\n",
    "        \"model__max_depth\": [3, 6, 10],\n",
    "        \"model__learning_rate\": [0.01, 0.1, 0.2]\n",
    "    },\n",
    "    # rfe requires coeff_ or feature importance, kNN doesnt have that\n",
    "    # \"knn\": {\n",
    "    #     \"rfe__n_features_to_select\": [5, 10, 15, 20, 25, 30],\n",
    "    #     \"model__n_neighbors\": [3, 5, 7, 9],\n",
    "    #     \"model__weights\": [\"uniform\", \"distance\"]\n",
    "    # },\n",
    "    \"gb\": {\n",
    "        \"rfe__n_features_to_select\": [ 30, 40, 50, 'all'],\n",
    "        \"model__n_estimators\": [50],\n",
    "        \"model__max_depth\": [3],\n",
    "        \"model__learning_rate\": [0.05]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ko8aHPyXOpe"
   },
   "source": [
    "we now define our models array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 127,
     "status": "ok",
     "timestamp": 1756803938614,
     "user": {
      "displayName": "Vivienne Bailo",
      "userId": "01903770756516003996"
     },
     "user_tz": -180
    },
    "id": "xBgaxewlUnL7"
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"lr\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"rf\": RandomForestClassifier(random_state=42),\n",
    "    \"svm\": SVC(random_state=42, probability=True),\n",
    "    \"xgb\": XGBClassifier(eval_metric='logloss', colsample_bytree=0.8, gamma=0, min_child_weight=1, subsample=0.6, random_state=42),\n",
    "    \"knn\": KNeighborsClassifier(),\n",
    "    \"gb\": GradientBoostingClassifier(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B9PkANeDXTlD"
   },
   "source": [
    "Training and Validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5452283,
     "status": "ok",
     "timestamp": 1756815466261,
     "user": {
      "displayName": "Vivienne Bailo",
      "userId": "01903770756516003996"
     },
     "user_tz": -180
    },
    "id": "091bc5bb",
    "outputId": "33505af8-0163-4b7d-8e65-832e544ee5f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running grid search for lr\n",
      "Fitting 65 folds for each of 24 candidates, totalling 1560 fits\n",
      "\n",
      "Best parameters for lr:\n",
      "  model__C: 0.1\n",
      "\n",
      "  model__penalty: l2\n",
      "\n",
      "  model__solver: lbfgs\n",
      "\n",
      "  rfe__n_features_to_select: 5\n",
      "\n",
      "\n",
      "Classification Report for lr:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.89      0.84         9\n",
      "           1       0.86      0.75      0.80         8\n",
      "\n",
      "    accuracy                           0.82        17\n",
      "   macro avg       0.83      0.82      0.82        17\n",
      "weighted avg       0.83      0.82      0.82        17\n",
      "\n",
      "\n",
      "Cross-validation scores for lr:\n",
      "Overall CV score: 0.8507 ± 0.1212\n",
      "Running grid search for svm\n",
      "Fitting 65 folds for each of 72 candidates, totalling 4680 fits\n",
      "\n",
      "Best parameters for svm:\n",
      "  model__C: 0.1\n",
      "\n",
      "  model__gamma: scale\n",
      "\n",
      "  model__kernel: linear\n",
      "\n",
      "  rfe__n_features_to_select: 5\n",
      "\n",
      "\n",
      "Classification Report for svm:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78         9\n",
      "           1       0.75      0.75      0.75         8\n",
      "\n",
      "    accuracy                           0.76        17\n",
      "   macro avg       0.76      0.76      0.76        17\n",
      "weighted avg       0.76      0.76      0.76        17\n",
      "\n",
      "\n",
      "Cross-validation scores for svm:\n",
      "Overall CV score: 0.8604 ± 0.1034\n",
      "Running grid search for rf\n",
      "Fitting 65 folds for each of 96 candidates, totalling 6240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters for rf:\n",
      "  model__max_depth: 5\n",
      "\n",
      "  model__min_samples_leaf: 1\n",
      "\n",
      "  model__min_samples_split: 5\n",
      "\n",
      "  model__n_estimators: 100\n",
      "\n",
      "  rfe__n_features_to_select: 30\n",
      "\n",
      "\n",
      "Classification Report for rf:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.89      0.80         9\n",
      "           1       0.83      0.62      0.71         8\n",
      "\n",
      "    accuracy                           0.76        17\n",
      "   macro avg       0.78      0.76      0.76        17\n",
      "weighted avg       0.78      0.76      0.76        17\n",
      "\n",
      "\n",
      "Cross-validation scores for rf:\n",
      "Overall CV score: 0.9190 ± 0.0708\n",
      "Running grid search for xgb\n",
      "Fitting 65 folds for each of 126 candidates, totalling 8190 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "1170 fits failed out of a total of 8190.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1170 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py\", line 654, in fit\n",
      "    Xt = self._fit(X, y, routed_params, raw_params=params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py\", line 588, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/joblib/memory.py\", line 326, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py\", line 1551, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/base.py\", line 921, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'n_features_to_select' parameter of RFE must be None, a float in the range (0.0, 1.0] or an int in the range (0, inf). Got 'all' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.52032967 0.63504274 0.9040293  0.94224664 0.93992674 0.93547009\n",
      "        nan 0.52667888 0.6452381  0.9042735  0.94084249 0.93699634\n",
      " 0.93656899        nan 0.52313797 0.63632479 0.90549451 0.94255189\n",
      " 0.94029304 0.93589744        nan 0.52918193 0.64200244 0.90549451\n",
      " 0.94090354 0.93699634 0.93547009        nan 0.52313797 0.63632479\n",
      " 0.90549451 0.94255189 0.94029304 0.93589744        nan 0.52918193\n",
      " 0.64200244 0.90549451 0.94090354 0.93699634 0.93547009        nan\n",
      " 0.53626374 0.64175824 0.88315018 0.91440781 0.90286935 0.89957265\n",
      "        nan 0.53369963 0.62771673 0.87692308 0.90726496 0.89181929\n",
      " 0.88327228        nan 0.53809524 0.64255189 0.88296703 0.91330891\n",
      " 0.9032967  0.90030525        nan 0.53504274 0.62997558 0.87655678\n",
      " 0.90763126 0.89181929 0.88400488        nan 0.53809524 0.64255189\n",
      " 0.88296703 0.91330891 0.9032967  0.90030525        nan 0.53504274\n",
      " 0.62997558 0.87655678 0.90763126 0.89181929 0.88400488        nan\n",
      " 0.54786325 0.62789988 0.87051282 0.9026862  0.89474969 0.89194139\n",
      "        nan 0.54023199 0.63028083 0.86746032 0.89590965 0.88827839\n",
      " 0.88571429        nan 0.53766789 0.64230769 0.86971917 0.9026862\n",
      " 0.8964591  0.89194139        nan 0.53021978 0.64059829 0.86831502\n",
      " 0.89590965 0.88956044 0.88571429        nan 0.53766789 0.64230769\n",
      " 0.86971917 0.9026862  0.8964591  0.89194139        nan 0.53021978\n",
      " 0.64059829 0.86831502 0.89590965 0.88956044 0.88571429        nan]\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters for xgb:\n",
      "  model__learning_rate: 0.01\n",
      "\n",
      "  model__max_depth: 6\n",
      "\n",
      "  model__n_estimators: 100\n",
      "\n",
      "  rfe__n_features_to_select: 30\n",
      "\n",
      "\n",
      "Classification Report for xgb:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78         9\n",
      "           1       0.75      0.75      0.75         8\n",
      "\n",
      "    accuracy                           0.76        17\n",
      "   macro avg       0.76      0.76      0.76        17\n",
      "weighted avg       0.76      0.76      0.76        17\n",
      "\n",
      "\n",
      "Cross-validation scores for xgb:\n",
      "Overall CV score: 0.9426 ± 0.0586\n",
      "Running grid search for gb\n",
      "Fitting 65 folds for each of 4 candidates, totalling 260 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "65 fits failed out of a total of 260.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "65 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py\", line 654, in fit\n",
      "    Xt = self._fit(X, y, routed_params, raw_params=params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py\", line 588, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/joblib/memory.py\", line 326, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/pipeline.py\", line 1551, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/utils/_set_output.py\", line 319, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/base.py\", line 921, in fit_transform\n",
      "    return self.fit(X, y, **fit_params).transform(X)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'n_features_to_select' parameter of RFE must be None, a float in the range (0.0, 1.0] or an int in the range (0, inf). Got 'all' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.83315018 0.84004884 0.83711844        nan]\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters for gb:\n",
      "  model__learning_rate: 0.05\n",
      "\n",
      "  model__max_depth: 3\n",
      "\n",
      "  model__n_estimators: 50\n",
      "\n",
      "  rfe__n_features_to_select: 40\n",
      "\n",
      "\n",
      "Classification Report for gb:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.78      0.74         9\n",
      "           1       0.71      0.62      0.67         8\n",
      "\n",
      "    accuracy                           0.71        17\n",
      "   macro avg       0.71      0.70      0.70        17\n",
      "weighted avg       0.71      0.71      0.70        17\n",
      "\n",
      "\n",
      "Cross-validation scores for gb:\n",
      "Overall CV score: 0.8400 ± 0.0911\n",
      "\n",
      "================================================================================\n",
      "MODELS RANKED BY TEST ACCURACY\n",
      "model  test_accuracy  test_precision  test_recall  test_f1  test_auc\n",
      "   lr       0.823529        0.826891     0.823529 0.822291  0.888889\n",
      "  svm       0.764706        0.764706     0.764706 0.764706  0.875000\n",
      "   rf       0.764706        0.777184     0.764706 0.759664  0.930556\n",
      "  xgb       0.764706        0.764706     0.764706 0.764706  0.847222\n",
      "   gb       0.705882        0.706723     0.705882 0.703818  0.743056\n"
     ]
    }
   ],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=8, n_repeats=15, random_state=123) #the cross validation method we'll use across models\n",
    "results = [] #to store metrics, accuracy scores and all other\n",
    "best_models={}\n",
    "\n",
    "\n",
    "for model_name, params in param_grid.items():\n",
    "    print(f\"Running grid search for {model_name}\")\n",
    "\n",
    "    base_model = models[model_name]\n",
    "\n",
    "    # rfe_estimator = LogisticRegression(max_iter=1000, random_state=42) if model_name == \"svm\" else clone(base_model)\n",
    "\n",
    "    if model_name in [\"lr\", \"svm\"]: #we directly excluded knn\n",
    "        # we use LR as the estimator\n",
    "        rfe_estimator = LogisticRegression(max_iter=1000, random_state=42) if model_name == \"svm\" else clone(base_model)\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('rfe', RFE(estimator=rfe_estimator)),\n",
    "            ('model', clone(base_model))\n",
    "        ])\n",
    "    elif model_name in [\"rf\", \"gb\", \"xgb\"]:\n",
    "        #no scaling for tree-based scaling\n",
    "        rfe_estimator = LinearSVC(random_state=42) #test, rfe_base_model vs. rfe_linear_svc\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('rfe', RFE(estimator=rfe_estimator)),\n",
    "            ('model', clone(base_model))\n",
    "        ])\n",
    "\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        pipeline, #this implements fit and predict functions\n",
    "        params, #our params to test\n",
    "        cv=cv,\n",
    "        scoring='roc_auc',\n",
    "        n_jobs=-1, # parallel computing, use all cores\n",
    "        verbose=1,\n",
    "        return_train_score=True, # to get training scores as well\n",
    "\n",
    "    )\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    #make predictions with the best model (meaning with best params)\n",
    "    y_pred = grid.best_estimator_.predict(X_test)\n",
    "    y_pred_proba = grid.best_estimator_.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "    # calculate metrics on the test set\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    test_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "\n",
    "    results.append({\n",
    "        'model': model_name,\n",
    "        'test_accuracy': accuracy,\n",
    "        'test_precision': precision,\n",
    "        'test_recall': recall,\n",
    "        'test_f1': f1,\n",
    "        'test_auc': test_auc,\n",
    "        'best_params': grid.best_params_,\n",
    "    })\n",
    "\n",
    "    best_models[model_name] = grid.best_estimator_\n",
    "\n",
    "    # display best parameters\n",
    "    print(f\"\\nBest parameters for {model_name}:\")\n",
    "    for param, value in grid.best_params_.items():\n",
    "        print(f\"  {param}: {value}\\n\")\n",
    "\n",
    "    # display classification report\n",
    "    print(f\"\\nClassification Report for {model_name}:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    #display AUC\n",
    "    print(f\"\\nTest AUC for {model_name}: {test_auc:.4f}\")\n",
    "\n",
    "    #display CV scores for each fold and overall\n",
    "    print(f\"\\nCross-validation scores for {model_name}:\")\n",
    "    cv_results = grid.cv_results_\n",
    "    mean_scores = cv_results['mean_test_score'][grid.best_index_]\n",
    "    std_scores = cv_results['std_test_score'][grid.best_index_]\n",
    "    print(f\"Overall CV score: {mean_scores:.4f} ± {std_scores:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# dispaly models sorted by auc\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"MODELS RANKED BY AUC SCORE\")\n",
    "print(results_df.sort_values('test_auc', ascending=False)[['model', 'test_auc', 'test_accuracy', 'test_precision', 'test_recall', 'test_f1']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 92319,
     "status": "ok",
     "timestamp": 1756815559925,
     "user": {
      "displayName": "Vivienne Bailo",
      "userId": "01903770756516003996"
     },
     "user_tz": -180
    },
    "id": "STm9sWeBrNS3",
    "outputId": "4b76c995-5bbb-4246-f0a3-44a3b69c509d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: Mean CV AUC = 0.8507 (±0.1212)\n",
      "svm: Mean CV AUC = 0.8604 (±0.1034)\n",
      "rf: Mean CV AUC = 0.9190 (±0.0708)\n",
      "xgb: Mean CV AUC = 0.9426 (±0.0586)\n",
      "gb: Mean CV AUC = 0.8400 (±0.0911)\n",
      "\n",
      "================================================================================\n",
      "MODELS RANKED BY MEAN CV AUC\n",
      "model  mean_cv_auc  std_cv_auc  test_auc\n",
      "  xgb     0.942552    0.058616  0.847222\n",
      "   rf     0.918987    0.070795  0.930556\n",
      "  svm     0.860440    0.103359  0.875000\n",
      "   lr     0.850733    0.121163  0.888889\n",
      "   gb     0.840049    0.091062  0.743056\n"
     ]
    }
   ],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=8, n_repeats=15, random_state=123) #the cross validation method we'll use across models\n",
    "cv_auc_scores = {}  #dict to store CV AUC scores for each model\n",
    "\n",
    "for model_name in best_models.keys():\n",
    "    #best parameters for the current model\n",
    "    best_params = results_df[results_df['model'] == model_name]['best_params'].iloc[0]\n",
    "\n",
    "    if model_name in [\"lr\", \"svm\"]:\n",
    "        rfe_estimator = LogisticRegression(max_iter=1000, random_state=42) if base_model_name == \"svm\" else clone(base_model)\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('rfe', RFE(estimator=rfe_estimator)),\n",
    "            ('model', clone(base_model))\n",
    "        ])\n",
    "    else:\n",
    "        rfe_estimator = LinearSVC(random_state=42)\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('rfe', RFE(estimator=rfe_estimator)),\n",
    "            ('model', clone(base_model))\n",
    "        ])\n",
    "    pipeline.set_params(**best_params)\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        pipeline,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        scoring='roc_auc',\n",
    "        cv=cv,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    cv_auc_scores[model_name] = {\n",
    "        'mean_cv_auc': scores.mean(),\n",
    "        'std_cv_auc': scores.std()\n",
    "    }\n",
    "\n",
    "    print(f\"{model_name}: Mean CV AUC = {scores.mean():.4f} (±{scores.std():.4f})\")\n",
    "\n",
    "#add CV AUC metrics to results_df so we can access them later\n",
    "results_df['mean_cv_auc'] = results_df['model'].map(lambda x: cv_auc_scores[x]['mean_cv_auc'])\n",
    "results_df['std_cv_auc'] = results_df['model'].map(lambda x: cv_auc_scores[x]['std_cv_auc'])\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"MODELS RANKED BY MEAN CV AUC\")\n",
    "print(results_df.sort_values('mean_cv_auc', ascending=False)[['model', 'mean_cv_auc', 'std_cv_auc', 'test_auc']].to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNohlnMq34rW8mXgdnIhHJs",
   "mount_file_id": "1n_kgfrYuWYL2XBE1wDIshZ_nr-VVGvup",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
