{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KtCsEtuLS8s4"
   },
   "source": [
    "for the run over the general methodology, refer to \"general_training_methodology.md\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UtruyBuA-PL1"
   },
   "source": [
    "Let's import the libraries we'll be needing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3594,
     "status": "ok",
     "timestamp": 1756831240886,
     "user": {
      "displayName": "Vivienne Bailo",
      "userId": "01903770756516003996"
     },
     "user_tz": -180
    },
    "id": "JaujOauy-Nm3"
   },
   "outputs": [],
   "source": [
    "#cross-validation & tuning\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.metrics import recall_score, f1_score, classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#dimensionality-reduction & tools\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkT7PYawX2JK"
   },
   "source": [
    "Let's import our data and define our train and test values. The 'label' column is the encoded output (0 for healthy control, 1 for Parkinson's disease). We'll split out train/test data, leaving a 20% holdout test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 256,
     "status": "ok",
     "timestamp": 1756831258129,
     "user": {
      "displayName": "Vivienne Bailo",
      "userId": "01903770756516003996"
     },
     "user_tz": -180
    },
    "id": "64y2B3UAX7Hk"
   },
   "outputs": [],
   "source": [
    "csv_path = \"D:\\\\projects\\\\final_PD\\\\openSMILE_GeMAPSv01b.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "X = df.drop(columns=['label', 'Sex', 'ID', 'Age'], axis=1)\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4tN9wCJ5_Ct9"
   },
   "source": [
    "parameter grid definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 249,
     "status": "ok",
     "timestamp": 1756831261876,
     "user": {
      "displayName": "Vivienne Bailo",
      "userId": "01903770756516003996"
     },
     "user_tz": -180
    },
    "id": "qR5i4rq--ibT"
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"lr\": {\n",
    "        \"select__k\": [5, 10, 15, 20, 25, 30], # Changed from pca__n_components\n",
    "        \"model__C\": [0.01, 0.1, 1, 10],\n",
    "        \"model__penalty\": [\"l2\"],\n",
    "        \"model__solver\": [\"lbfgs\"]\n",
    "    },\n",
    "    \"svm\": {\n",
    "        \"select__k\": [5, 10, 15, 20, 25, 30], # Changed from pca__n_components\n",
    "        \"model__C\": [0.1, 1, 10],\n",
    "        \"model__kernel\": [\"linear\", \"rbf\"],\n",
    "        \"model__gamma\": [\"scale\", \"auto\"]\n",
    "    },\n",
    "    \"rf\": {\n",
    "        \"select__k\": [5, 10, 15, 20, 25, 30, 'all'], # Added select__k for tree models as well\n",
    "        \"model__n_estimators\": [50, 100],\n",
    "        \"model__max_depth\": [3, 5],\n",
    "        \"model__min_samples_split\": [5, 10],\n",
    "        \"model__min_samples_leaf\": [1, 5]\n",
    "    },\n",
    "    \"xgb\": {\n",
    "        \"select__k\": [5, 10, 15, 20, 25, 30, 'all'], # Added select__k for tree models as well\n",
    "        \"model__n_estimators\": [100, 200],\n",
    "        \"model__max_depth\": [3, 6, 10],\n",
    "        \"model__learning_rate\": [0.01, 0.1, 0.2]\n",
    "    },\n",
    "    \"knn\": {\n",
    "        \"select__k\": [5, 10, 15, 20, 25, 30], # Changed from pca__n_components\n",
    "        \"model__n_neighbors\": [3, 5, 7, 9],\n",
    "        \"model__weights\": [\"uniform\", \"distance\"]\n",
    "    },\n",
    "    \"gb\": {\n",
    "        \"select__k\": [40], # Added select__k for tree models as well\n",
    "        \"model__n_estimators\": [50, 100],\n",
    "        \"model__max_depth\": [3, 5],\n",
    "        \"model__learning_rate\": [0.05, 0.1]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ko8aHPyXOpe"
   },
   "source": [
    "we now define our models array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 73,
     "status": "ok",
     "timestamp": 1756831263546,
     "user": {
      "displayName": "Vivienne Bailo",
      "userId": "01903770756516003996"
     },
     "user_tz": -180
    },
    "id": "xBgaxewlUnL7"
   },
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"lr\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"rf\": RandomForestClassifier(random_state=42),\n",
    "    \"svm\": SVC(random_state=42, probability=True),\n",
    "    \"xgb\": XGBClassifier(eval_metric='logloss', colsample_bytree=0.8, gamma=0, min_child_weight=1, subsample=0.6, random_state=42),\n",
    "    \"knn\": KNeighborsClassifier(),\n",
    "    \"gb\": GradientBoostingClassifier(random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B9PkANeDXTlD"
   },
   "source": [
    "Training and Validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1510039,
     "status": "ok",
     "timestamp": 1756832775491,
     "user": {
      "displayName": "Vivienne Bailo",
      "userId": "01903770756516003996"
     },
     "user_tz": -180
    },
    "id": "091bc5bb",
    "outputId": "39f087b4-c4bb-4e3f-df93-aba390b7946b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running grid search for lr\n",
      "Fitting 65 folds for each of 24 candidates, totalling 1560 fits\n",
      "\n",
      "Best parameters for lr:\n",
      "  model__C: 0.01\n",
      "\n",
      "  model__penalty: l2\n",
      "\n",
      "  model__solver: lbfgs\n",
      "\n",
      "  select__k: 30\n",
      "\n",
      "\n",
      "Classification Report for lr:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.78      0.74         9\n",
      "           1       0.71      0.62      0.67         8\n",
      "\n",
      "    accuracy                           0.71        17\n",
      "   macro avg       0.71      0.70      0.70        17\n",
      "weighted avg       0.71      0.71      0.70        17\n",
      "\n",
      "AUC: lr: 0.7639\n",
      "Running grid search for svm\n",
      "Fitting 65 folds for each of 72 candidates, totalling 4680 fits\n",
      "\n",
      "Best parameters for svm:\n",
      "  model__C: 0.1\n",
      "\n",
      "  model__gamma: scale\n",
      "\n",
      "  model__kernel: linear\n",
      "\n",
      "  select__k: 30\n",
      "\n",
      "\n",
      "Classification Report for svm:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.78      0.74         9\n",
      "           1       0.71      0.62      0.67         8\n",
      "\n",
      "    accuracy                           0.71        17\n",
      "   macro avg       0.71      0.70      0.70        17\n",
      "weighted avg       0.71      0.71      0.70        17\n",
      "\n",
      "AUC: svm: 0.7778\n",
      "Running grid search for rf\n",
      "Fitting 65 folds for each of 112 candidates, totalling 7280 fits\n",
      "\n",
      "Best parameters for rf:\n",
      "  model__max_depth: 5\n",
      "\n",
      "  model__min_samples_leaf: 1\n",
      "\n",
      "  model__min_samples_split: 5\n",
      "\n",
      "  model__n_estimators: 100\n",
      "\n",
      "  select__k: all\n",
      "\n",
      "\n",
      "Classification Report for rf:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      1.00      0.82         9\n",
      "           1       1.00      0.50      0.67         8\n",
      "\n",
      "    accuracy                           0.76        17\n",
      "   macro avg       0.85      0.75      0.74        17\n",
      "weighted avg       0.84      0.76      0.75        17\n",
      "\n",
      "AUC: rf: 0.9167\n",
      "Running grid search for xgb\n",
      "Fitting 65 folds for each of 126 candidates, totalling 8190 fits\n",
      "\n",
      "Best parameters for xgb:\n",
      "  model__learning_rate: 0.01\n",
      "\n",
      "  model__max_depth: 6\n",
      "\n",
      "  model__n_estimators: 200\n",
      "\n",
      "  select__k: 15\n",
      "\n",
      "\n",
      "Classification Report for xgb:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.67      0.71         9\n",
      "           1       0.67      0.75      0.71         8\n",
      "\n",
      "    accuracy                           0.71        17\n",
      "   macro avg       0.71      0.71      0.71        17\n",
      "weighted avg       0.71      0.71      0.71        17\n",
      "\n",
      "AUC: xgb: 0.7639\n",
      "Running grid search for knn\n",
      "Fitting 65 folds for each of 48 candidates, totalling 3120 fits\n",
      "\n",
      "Best parameters for knn:\n",
      "  model__n_neighbors: 9\n",
      "\n",
      "  model__weights: uniform\n",
      "\n",
      "  select__k: 5\n",
      "\n",
      "\n",
      "Classification Report for knn:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.89      0.80         9\n",
      "           1       0.83      0.62      0.71         8\n",
      "\n",
      "    accuracy                           0.76        17\n",
      "   macro avg       0.78      0.76      0.76        17\n",
      "weighted avg       0.78      0.76      0.76        17\n",
      "\n",
      "AUC: knn: 0.7014\n",
      "Running grid search for gb\n",
      "Fitting 65 folds for each of 8 candidates, totalling 520 fits\n",
      "\n",
      "Best parameters for gb:\n",
      "  model__learning_rate: 0.1\n",
      "\n",
      "  model__max_depth: 3\n",
      "\n",
      "  model__n_estimators: 50\n",
      "\n",
      "  select__k: 40\n",
      "\n",
      "\n",
      "Classification Report for gb:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.67      0.75         9\n",
      "           1       0.70      0.88      0.78         8\n",
      "\n",
      "    accuracy                           0.76        17\n",
      "   macro avg       0.78      0.77      0.76        17\n",
      "weighted avg       0.78      0.76      0.76        17\n",
      "\n",
      "AUC: gb: 0.7917\n"
     ]
    }
   ],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=8, n_repeats=15, random_state=123) #the cross validation method we'll use across models\n",
    "results = [] #to store metrics, accuracy scores and all other\n",
    "best_models={}\n",
    "\n",
    "for model_name, params in param_grid.items():\n",
    "    print(f\"Running grid search for {model_name}\")\n",
    "\n",
    "    #creating different pipelines\n",
    "\n",
    "    if model_name in [\"rf\", \"xgb\", \"gb\"]:\n",
    "        # tree-based models without scaling\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('select', SelectKBest(score_func=f_classif)),\n",
    "            ('model', models[model_name])\n",
    "        ])\n",
    "\n",
    "    else:\n",
    "        #other models using SelectKBest with scaling\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('select', SelectKBest(score_func=f_classif)), # Changed from PCA()\n",
    "            ('model', models[model_name])\n",
    "        ])\n",
    "\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        pipeline, #this implements fit and predict functions\n",
    "        params, #our params to test\n",
    "        cv=cv,\n",
    "        scoring='roc_auc',\n",
    "        n_jobs=-1, # parallel computing, use all cores\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    #make predictions with the best model (meaning with best params)\n",
    "    y_pred = grid.best_estimator_.predict(X_test)\n",
    "    y_pred_proba = grid.best_estimator_.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # calculate metrics on the test set\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    test_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    results.append({\n",
    "        'model': model_name,\n",
    "        'best_score': grid.best_score_,\n",
    "        'test_accuracy': accuracy,\n",
    "        'test_precision': precision,\n",
    "        'test_recall': recall,\n",
    "        'test_f1': f1,\n",
    "        'best_params': grid.best_params_,\n",
    "        'test_auc': test_auc,\n",
    "        'confusion_matrix': confusion_matrix(y_test, y_pred)\n",
    "    })\n",
    "\n",
    "    best_models[model_name] = grid.best_estimator_\n",
    "\n",
    "    # display best parameters\n",
    "    print(f\"\\nBest parameters for {model_name}:\")\n",
    "    for param, value in grid.best_params_.items():\n",
    "        print(f\"  {param}: {value}\\n\")\n",
    "\n",
    "    # display classification report\n",
    "    print(f\"\\nClassification Report for {model_name}:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"AUC: {model_name}: {test_auc:.4f}\")\n",
    "\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21507,
     "status": "ok",
     "timestamp": 1756832800607,
     "user": {
      "displayName": "Vivienne Bailo",
      "userId": "01903770756516003996"
     },
     "user_tz": -180
    },
    "id": "ZMcb8YkGmqcz",
    "outputId": "ba3a8ca0-5d01-46a6-f348-5c8568051e3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: Mean CV AUC = 0.6416 (±0.1467)\n",
      "svm: Mean CV AUC = 0.6369 (±0.1349)\n",
      "rf: Mean CV AUC = 0.6538 (±0.1529)\n",
      "xgb: Mean CV AUC = 0.6451 (±0.1480)\n",
      "knn: Mean CV AUC = 0.6241 (±0.1331)\n",
      "gb: Mean CV AUC = 0.6227 (±0.1819)\n",
      "\n",
      "================================================================================\n",
      "MODELS RANKED BY MEAN CV AUC\n",
      "model  mean_cv_auc  std_cv_auc  test_auc\n",
      "   rf     0.653846    0.152940  0.916667\n",
      "  xgb     0.645116    0.148045  0.763889\n",
      "   lr     0.641575    0.146747  0.763889\n",
      "  svm     0.636874    0.134941  0.777778\n",
      "  knn     0.624084    0.133144  0.701389\n",
      "   gb     0.622711    0.181853  0.791667\n"
     ]
    }
   ],
   "source": [
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=13, random_state=123) #the cross validation method we'll use across models\n",
    "cv_auc_scores = {}  # Dictionary to store CV AUC scores for each model\n",
    "\n",
    "for model_name in best_models.keys():\n",
    "    # Get the best parameters for the current model\n",
    "    best_params = results_df[results_df['model'] == model_name]['best_params'].iloc[0]\n",
    "\n",
    "    if model_name in [\"rf\", \"xgb\", \"gb\"]:\n",
    "        # tree-based models, SelectKBest without scaling\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('select', SelectKBest(score_func=f_classif)),\n",
    "            ('model', models[model_name])\n",
    "        ])\n",
    "\n",
    "    else:\n",
    "        # other models using SelectKBest with scaling\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('select', SelectKBest(score_func=f_classif)), # Changed from PCA()\n",
    "            ('model', models[model_name])\n",
    "        ])\n",
    "    pipeline.set_params(**best_params)\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        pipeline,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        scoring='roc_auc',\n",
    "        cv=cv,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    cv_auc_scores[model_name] = {\n",
    "        'mean_cv_auc': scores.mean(),\n",
    "        'std_cv_auc': scores.std()\n",
    "    }\n",
    "\n",
    "    print(f\"{model_name}: Mean CV AUC = {scores.mean():.4f} (±{scores.std():.4f})\")\n",
    "\n",
    "#add CV AUC metrics to results_df so we can access them later\n",
    "results_df['mean_cv_auc'] = results_df['model'].map(lambda x: cv_auc_scores[x]['mean_cv_auc'])\n",
    "results_df['std_cv_auc'] = results_df['model'].map(lambda x: cv_auc_scores[x]['std_cv_auc'])\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"MODELS RANKED BY MEAN CV AUC\")\n",
    "print(results_df.sort_values('mean_cv_auc', ascending=False)[['model', 'mean_cv_auc', 'std_cv_auc', 'test_auc']].to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOA3arFSMwkseqxUR2fPAPJ",
   "mount_file_id": "15d_N4rm62CBjT5PTQxsy3m6r2FWT0GRo",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
